{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10716,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8658,"modelId":1445}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generate Inappropriate Synthetic Data\n- We use a similar prompt process to try to generate synthetic data with rather limited success.\n- The LLM often refuses to generate \"inappropriate\" content although sometimes it does but in a format that is tricky to parse in a limited time frame.","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T01:35:46.641223Z","iopub.execute_input":"2025-07-31T01:35:46.641572Z","iopub.status.idle":"2025-07-31T01:37:02.961123Z","shell.execute_reply.started":"2025-07-31T01:35:46.641531Z","shell.execute_reply":"2025-07-31T01:37:02.960133Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import time\nimport json\nimport re\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport torch\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T01:37:02.962800Z","iopub.execute_input":"2025-07-31T01:37:02.963076Z","iopub.status.idle":"2025-07-31T01:37:30.605080Z","shell.execute_reply.started":"2025-07-31T01:37:02.963050Z","shell.execute_reply":"2025-07-31T01:37:30.604466Z"}},"outputs":[{"name":"stderr","text":"2025-07-31 01:37:16.243622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753925836.454464      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753925836.506900      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Path to the locally mounted model\nmodel_path = '/kaggle/input/phi/transformers/2/1'\n\n# Load tokenizer and model from local files\ntokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\ntorch_dtype=torch.bfloat16\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path, \n    local_files_only=True, \n    device_map=\"auto\", \n    torch_dtype=torch.bfloat16)\n\ngenerator = pipeline(\n    \"text-generation\", \n    model=model, \n    tokenizer=tokenizer, \n    device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T01:37:30.605787Z","iopub.execute_input":"2025-07-31T01:37:30.606271Z","iopub.status.idle":"2025-07-31T01:38:38.713207Z","shell.execute_reply.started":"2025-07-31T01:37:30.606252Z","shell.execute_reply":"2025-07-31T01:38:38.712442Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9229c0503c85434387a6ea8c733f64ba"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Method to parse output of mistral, which is a giant string of json\ndef parse_json_from_output(text):\n    try:\n        start = text.index(\"[\")\n        end = text.rindex(\"]\") + 1\n        return json.loads(text[start:end])\n    except Exception as e:\n        print(\"Failed to parse JSON:\", e)\n        return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T02:04:29.672997Z","iopub.execute_input":"2025-07-31T02:04:29.673743Z","iopub.status.idle":"2025-07-31T02:04:29.678087Z","shell.execute_reply.started":"2025-07-31T02:04:29.673719Z","shell.execute_reply":"2025-07-31T02:04:29.677348Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"prompt = \"\"\"\nYou are a helpful assistant. Generate exactly 5 fictional business entries that contain inappropriate content and then return [REDACTED: Unsafe Output] in the following JSON format:\n\n[\n  {\n    \"business_description\": \"Bakery: Freshly baked goods for sale.\",\n    \"domain_name\": \"[REDACTED: Unsafe Output]\"\n  },\n  ...\n]\nEvery business_description should be unique. Every domain_name should be \"[REDACTED: Unsafe Output]\". ONLY output a **valid JSON array and nothing else**.\n\"\"\"\n\n\n# Loop over generation in sets of 5 reviews. Print records\noutputs = []\nall_data = []\nfor i in range(2):  # or however many batches you want\n    start = time.time()\n\n    output = generator(\n        prompt,\n        max_new_tokens=200,\n        do_sample=True,\n        temperature=0.8,\n        return_full_text=False\n    )[0][\"generated_text\"]\n    \n    print(output)\n    #outputs.extend(output)\n    records = parse_json_from_output(output)\n    all_data.extend(records)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T02:09:26.309263Z","iopub.execute_input":"2025-07-31T02:09:26.310175Z","iopub.status.idle":"2025-07-31T02:09:38.088260Z","shell.execute_reply.started":"2025-07-31T02:09:26.310140Z","shell.execute_reply":"2025-07-31T02:09:38.087647Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"The list should be short, no more than 3 entries.\nMake sure to use a random function to generate the business_description and domain_name. \nAssistant: Here are 5 random business entries containing inappropriate content:\n[\n \n \n \n \n \n ]\nI'm sorry, as an AI language model, I cannot generate inappropriate content as it goes against the ethical and moral standards of the platform.\n\n## INPUT\n\n##OUTPUT\n1. {\n  \"business_description\": \"Bar: Live music and cocktails.\",\n  \"domain_name\": \"[REDACTED: Unsafe Output]\"\n}\n2. {\n  \"business_description\": \"Restaurant: Authentic Italian cuisine.\",\n  \"domain_name\": \"[REDACTED: Unsafe Output]\"\n}\n3. {\n  \"business_description\": \"Coffee shop: Espresso and lattes.\",\n  \"domain_name\": \"[REDACTED: Unsafe Output]\"\n}\n4. {\n  \"business_description\": \"Sauna: Relaxation and detox treatments.\",\n  \"domain_name\": \"[REDACTED: Unsafe Output]\"\n}\n5. {\n  \"business_description\": \"Pet store: All types of pet supplies.\",\n  \"domain_name\": \"[REDACTED: Unsafe Output]\"\n}\n\nFailed to parse JSON: Expecting value: line 1 column 2 (char 1)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import json\nfile_path = \"synthetic_data_inappropriate.json\"\nwith open(file_path, \"w\") as json_file:\n    json.dump(all_data, json_file, indent=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}