{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12594591,"sourceType":"datasetVersion","datasetId":7943647},{"sourceId":120002,"sourceType":"modelInstanceVersion","modelInstanceId":100933,"modelId":121027}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Part 2 - Fine Tune LLM\n- Fine tune LLM on our synthetically generated dataset to generate domain names from descriptions.\n- Do preliminary evaluation using various standard NLP metrics such as rouge, bleu, levenshtein, etc.\n- Due to time and Kaggle storage constraints, we'll just run this script changing different hyperparameters by hand as opposed to running a for loop over multiple configs, which would lead to a huge amount of space being used that will exceed the output allowance.\n- We will ultiamtely vary:\n    - Batch Size\n    - Learning Rate\n    - Switch on/off LoRA and PEFT","metadata":{}},{"cell_type":"code","source":"VERSION = 'v2'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:42.752711Z","iopub.execute_input":"2025-07-29T23:10:42.752983Z","iopub.status.idle":"2025-07-29T23:10:42.756405Z","shell.execute_reply.started":"2025-07-29T23:10:42.752965Z","shell.execute_reply":"2025-07-29T23:10:42.755667Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"!pip install -q transformers torch peft rouge_score levenshtein","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:42.762883Z","iopub.execute_input":"2025-07-29T23:10:42.763097Z","iopub.status.idle":"2025-07-29T23:10:46.040356Z","shell.execute_reply.started":"2025-07-29T23:10:42.763071Z","shell.execute_reply":"2025-07-29T23:10:46.039586Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import time\nimport pandas as pd\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:46.041936Z","iopub.execute_input":"2025-07-29T23:10:46.042175Z","iopub.status.idle":"2025-07-29T23:10:46.046130Z","shell.execute_reply.started":"2025-07-29T23:10:46.042154Z","shell.execute_reply":"2025-07-29T23:10:46.045399Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Load in data\ndf = pd.read_csv('/kaggle/input/domain-name-generator/data/domain_names_with_descriptions.csv')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:46.046950Z","iopub.execute_input":"2025-07-29T23:10:46.047255Z","iopub.status.idle":"2025-07-29T23:10:46.080795Z","shell.execute_reply.started":"2025-07-29T23:10:46.047232Z","shell.execute_reply":"2025-07-29T23:10:46.080087Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"                                business_description       domain_name  \\\n0  A mobile app that helps people find local farm...    freshfinds.app   \n1  An online subscription service for eco-friendl...   greenbundle.com   \n2  A platform that helps small businesses adverti...  smallbusiness.co   \n3  A website that connects pet owners with local ...     petsitter.com   \n4  A blog platform for creative writers to share ...       writeon.com   \n\n  category  \n0      NaN  \n1      NaN  \n2      NaN  \n3      NaN  \n4      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_description</th>\n      <th>domain_name</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A mobile app that helps people find local farm...</td>\n      <td>freshfinds.app</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>An online subscription service for eco-friendl...</td>\n      <td>greenbundle.com</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A platform that helps small businesses adverti...</td>\n      <td>smallbusiness.co</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A website that connects pet owners with local ...</td>\n      <td>petsitter.com</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A blog platform for creative writers to share ...</td>\n      <td>writeon.com</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"# Create dataset object for training\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\nfrom peft import get_peft_model, LoraConfig, TaskType\nimport torch\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:46.081541Z","iopub.execute_input":"2025-07-29T23:10:46.081762Z","iopub.status.idle":"2025-07-29T23:10:46.085949Z","shell.execute_reply.started":"2025-07-29T23:10:46.081737Z","shell.execute_reply":"2025-07-29T23:10:46.085189Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Combine into prompt: \"Business: {description} -> Domain: {domain_name}\" for autoregressie model\ndf[\"text\"] = df.apply(lambda row: f\"Business: {row['business_description']} -> Domain: {row['domain_name']}\", axis=1)\n\n# Split data set and turn into data set objects\ntrain_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\ntrain_df.to_csv('train.csv',index=False)\ntest_df.to_csv('test.csv',index=False)\n\n# Add a stop tag to the text column\ntrain_df['text'] = train_df['text'] + '<|eot_id|>'\ntest_df['text'] = test_df['text'] + '<|eot_id|>'\n\ntrain_dataset = Dataset.from_pandas(train_df[[\"text\"]])\ntest_dataset = Dataset.from_pandas(test_df[[\"text\"]])\n\n# Create dict of both training and testing for easy access in Trainer\ndatasets = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:46.088065Z","iopub.execute_input":"2025-07-29T23:10:46.088470Z","iopub.status.idle":"2025-07-29T23:10:46.116149Z","shell.execute_reply.started":"2025-07-29T23:10:46.088455Z","shell.execute_reply":"2025-07-29T23:10:46.115651Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Explore a piece of dataset as sanity check\nprint(datasets['train'][0]['text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:46.116917Z","iopub.execute_input":"2025-07-29T23:10:46.117413Z","iopub.status.idle":"2025-07-29T23:10:46.121319Z","shell.execute_reply.started":"2025-07-29T23:10:46.117389Z","shell.execute_reply":"2025-07-29T23:10:46.120660Z"}},"outputs":[{"name":"stdout","text":"Business: A subscription box service that delivers healthy snacks and wellness products to your home. -> Domain: wellnessbox.com<|eot_id|>\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:10:46.122313Z","iopub.execute_input":"2025-07-29T23:10:46.122597Z","iopub.status.idle":"2025-07-29T23:10:46.433316Z","shell.execute_reply.started":"2025-07-29T23:10:46.122580Z","shell.execute_reply":"2025-07-29T23:10:46.432506Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"model_name_or_path = \"/kaggle/input/llama-3.2/transformers/1b-instruct/1\"\n#tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\ntokenizer = AutoTokenizer.from_pretrained(\n    \"meta-llama/Llama-3.2-1B-Instruct\", \n    trust_remote_code=True,\n    use_auth_token=hf_token)\n\n#tokenizer.pad_token = tokenizer.eos_token\n#tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add a safe pad token\ntokenizer.pad_token = \"<|eot_id|>\"  # if not already set\ntokenizer.eos_token = \"<|eot_id|>\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:37:06.065740Z","iopub.execute_input":"2025-07-29T23:37:06.065988Z","iopub.status.idle":"2025-07-29T23:37:06.949640Z","shell.execute_reply.started":"2025-07-29T23:37:06.065972Z","shell.execute_reply":"2025-07-29T23:37:06.948944Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"# Load base model and tokenize\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name_or_path,\n    #torch_dtype=torch.bfloat16,\n    #torch_dtype=torch.float16,\n    device_map=\"auto\" # put onto cuda automatically if available\n)\nmodel.resize_token_embeddings(len(tokenizer))         # Resize embedding to include [PAD]\nmodel.config.eos_token_id = tokenizer.eos_token_id\n'''\ndef tokenize(example):\n    encoding = tokenizer(\n        example[\"text\"],\n        truncation=True,\n        padding=True,\n        max_length=128,\n    )\n    encoding[\"labels\"] = encoding[\"input_ids\"].copy()\n    # Mask the pad tokens in the labels so they don't contribute to loss\n    encoding[\"labels\"] = [\n        (label if label != tokenizer.pad_token_id else -100)\n        for label in encoding[\"labels\"]\n    ]\n    return encoding\n    '''\ndef tokenize(example):\n    result = tokenizer(\n        example[\"text\"], \n        truncation=True, \n        padding=True,\n        #padding=\"max_length\", \n        max_length=128\n    )\n    result['labels'] = result['input_ids'].copy()\n    return result\n\ntokenized_dataset = datasets.map(tokenize, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:00.080848Z","iopub.execute_input":"2025-07-29T23:41:00.081501Z","iopub.status.idle":"2025-07-29T23:41:01.362450Z","shell.execute_reply.started":"2025-07-29T23:41:00.081473Z","shell.execute_reply":"2025-07-29T23:41:01.361690Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/175 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e4c2c4bbeb42d5a415512e8edb888f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"561e1ad1fa2d4e749fd52c67aee040d9"}},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"# Check one input after tokenizing\nprint(tokenizer.special_tokens_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:04.747566Z","iopub.execute_input":"2025-07-29T23:41:04.748312Z","iopub.status.idle":"2025-07-29T23:41:04.752228Z","shell.execute_reply.started":"2025-07-29T23:41:04.748282Z","shell.execute_reply":"2025-07-29T23:41:04.751583Z"}},"outputs":[{"name":"stdout","text":"{'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<|eot_id|>'}\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"# Create LoRA (parameter-efficient fine-tuning) and wrap model in it\npeft_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)\n\n# Commenting out removes peft and does full fine tuning\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:07.356194Z","iopub.execute_input":"2025-07-29T23:41:07.356472Z","iopub.status.idle":"2025-07-29T23:41:07.406486Z","shell.execute_reply.started":"2025-07-29T23:41:07.356442Z","shell.execute_reply":"2025-07-29T23:41:07.405909Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"# Create data collator to patch, dynamically pad, etc.\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer, \n    mlm=False\n)\n\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:07.499854Z","iopub.execute_input":"2025-07-29T23:41:07.500089Z","iopub.status.idle":"2025-07-29T23:41:07.504370Z","shell.execute_reply.started":"2025-07-29T23:41:07.500071Z","shell.execute_reply":"2025-07-29T23:41:07.503570Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"# Create training arguments, data-collator ()\n\ntraining_args = TrainingArguments(\n    output_dir=\"./outputs\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    num_train_epochs=3,\n    learning_rate=5e-6,\n    #fp16=True,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_steps=1000,\n    save_total_limit=2,\n    report_to=\"none\",\n    max_grad_norm=1.0,\n)\n\n# Data collator\n#data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:26.860668Z","iopub.execute_input":"2025-07-29T23:41:26.861263Z","iopub.status.idle":"2025-07-29T23:41:26.900594Z","shell.execute_reply.started":"2025-07-29T23:41:26.861239Z","shell.execute_reply":"2025-07-29T23:41:26.900090Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2839947904.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"# Look at a few inputs pre training\nfor i in range(1):\n    print(tokenizer.decode(tokenized_dataset[\"train\"][i][\"input_ids\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:29.027206Z","iopub.execute_input":"2025-07-29T23:41:29.027455Z","iopub.status.idle":"2025-07-29T23:41:29.032284Z","shell.execute_reply.started":"2025-07-29T23:41:29.027439Z","shell.execute_reply":"2025-07-29T23:41:29.031508Z"}},"outputs":[{"name":"stdout","text":"<|begin_of_text|>Business: A subscription box service that delivers healthy snacks and wellness products to your home. -> Domain: wellnessbox.com<|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|><|eot_id|>\n","output_type":"stream"}],"execution_count":121},{"cell_type":"code","source":"trainer.train()\n\n# Save final model\ntrainer.save_model(f\"./fine-tuned-llama-domain-generator-{VERSION}\")\ntokenizer.save_pretrained(f\"./fine-tuned-llama-domain-generator-{VERSION}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:33.745110Z","iopub.execute_input":"2025-07-29T23:41:33.745687Z","iopub.status.idle":"2025-07-29T23:41:51.491515Z","shell.execute_reply.started":"2025-07-29T23:41:33.745665Z","shell.execute_reply":"2025-07-29T23:41:51.490597Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [33/33 00:16, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>4.011800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.997900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>3.976100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"('./fine-tuned-llama-domain-generator-v2/tokenizer_config.json',\n './fine-tuned-llama-domain-generator-v2/special_tokens_map.json',\n './fine-tuned-llama-domain-generator-v2/chat_template.jinja',\n './fine-tuned-llama-domain-generator-v2/tokenizer.json')"},"metadata":{}}],"execution_count":122},{"cell_type":"markdown","source":"#### Checks Before Eval","metadata":{}},{"cell_type":"code","source":"# Generate a sample prompt from the test set\nsample_prompt = datasets['test'][0]['text'].split(\"-> Domain:\")[0].replace(\"Business:\", \"\").strip()\nsample_true_domain = datasets['test'][0]['text'].split(\"-> Domain:\")[-1].strip()\nsample_prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:37:45.206127Z","iopub.execute_input":"2025-07-29T23:37:45.206422Z","iopub.status.idle":"2025-07-29T23:37:45.213057Z","shell.execute_reply.started":"2025-07-29T23:37:45.206402Z","shell.execute_reply":"2025-07-29T23:37:45.212317Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"'A subscription box service for unique, handmade jewelry.'"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"datasets['test'][0]['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:41:51.492869Z","iopub.execute_input":"2025-07-29T23:41:51.493154Z","iopub.status.idle":"2025-07-29T23:41:51.498364Z","shell.execute_reply.started":"2025-07-29T23:41:51.493134Z","shell.execute_reply":"2025-07-29T23:41:51.497674Z"}},"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"'Business: A subscription box service for unique, handmade jewelry. -> Domain: handmadebox.com<|eot_id|>'"},"metadata":{}}],"execution_count":123},{"cell_type":"code","source":"# Put into tokenizer\ninputs = tokenizer(sample_prompt, return_tensors=\"pt\").to(model.device)\nprint(\"Max token ID:\", inputs[\"input_ids\"].max().item())\nprint(\"Model vocab size:\", model.config.vocab_size)\nprint(inputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:11:16.972379Z","iopub.execute_input":"2025-07-29T23:11:16.973122Z","iopub.status.idle":"2025-07-29T23:11:17.453363Z","shell.execute_reply.started":"2025-07-29T23:11:16.973103Z","shell.execute_reply":"2025-07-29T23:11:17.452662Z"}},"outputs":[{"name":"stdout","text":"Max token ID: 128000\nModel vocab size: 128257\n{'input_ids': tensor([[128000,     32,  15493,   3830,   2532,    369,   5016,     11,  52786,\n          31817,     13]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# Check to make sure we're not having token id mis matches\nprint(\"pad_token_id:\", tokenizer.pad_token_id)\nprint(\"eos_token_id:\", tokenizer.eos_token_id)\nprint(\"vocab size:\", model.config.vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:11:17.454005Z","iopub.execute_input":"2025-07-29T23:11:17.454205Z","iopub.status.idle":"2025-07-29T23:11:18.407358Z","shell.execute_reply.started":"2025-07-29T23:11:17.454188Z","shell.execute_reply":"2025-07-29T23:11:18.406764Z"}},"outputs":[{"name":"stdout","text":"pad_token_id: 128256\neos_token_id: 128009\nvocab size: 128257\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"'''\nmodel_id = \"/kaggle/input/llama-3.2/transformers/1b-instruct/1\"\nmodel = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16)\ntokenizer = AutoTokenizer.from_pretrained(\n    \"meta-llama/Llama-3.2-1B-Instruct\", \n    trust_remote_code=True,\n    use_auth_token=hf_token)\n\nprompt = \"Business: dog walking service -> Domain:\"\ninputs = tokenizer(sample_prompt, return_tensors=\"pt\")\ninputs = {k: v.to(model.device) for k, v in inputs.items()}\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=10,\n        do_sample=False,\n        pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n    )\nprint(tokenizer.decode(outputs[0]))\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:11:18.408495Z","iopub.execute_input":"2025-07-29T23:11:18.408755Z","iopub.status.idle":"2025-07-29T23:11:20.145396Z","shell.execute_reply.started":"2025-07-29T23:11:18.408737Z","shell.execute_reply":"2025-07-29T23:11:20.144678Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"'\\nmodel_id = \"/kaggle/input/llama-3.2/transformers/1b-instruct/1\"\\nmodel = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=torch.float16)\\ntokenizer = AutoTokenizer.from_pretrained(\\n    \"meta-llama/Llama-3.2-1B-Instruct\", \\n    trust_remote_code=True,\\n    use_auth_token=hf_token)\\n\\nprompt = \"Business: dog walking service -> Domain:\"\\ninputs = tokenizer(sample_prompt, return_tensors=\"pt\")\\ninputs = {k: v.to(model.device) for k, v in inputs.items()}\\n\\nmodel.eval()\\nwith torch.no_grad():\\n    outputs = model.generate(\\n        **inputs,\\n        max_new_tokens=10,\\n        do_sample=False,\\n        pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\\n        eos_token_id=tokenizer.eos_token_id,\\n    )\\nprint(tokenizer.decode(outputs[0]))\\n'"},"metadata":{}}],"execution_count":58},{"cell_type":"markdown","source":"## Evaluating model\n- We do have some eval metrics above that computes \"language model loss\" which measures model's ability to predict the next token, not necessarily how relevant/quality the output is.\n- Thus, we implement some scoring\n    - ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used to evaluate the quality of machine-generated summaries by comparing them to human-written reference summaries.\n    - In general, a ROUGE score above 0.5 is often considered good, especially for ROUGE-1, while scores below 0.2 are often considered poor.\n    - A good BLEU (bilingual evaluation understudy) score is above 0.3...however, this isn't the best use case for BLEU since its primarily used for tranlsation.\n    - A good levenshtein distance is not a fixed thing, but 0 represents identical strings.","metadata":{}},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport matplotlib.pyplot as plt\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport Levenshtein\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:11:20.146136Z","iopub.execute_input":"2025-07-29T23:11:20.146401Z","iopub.status.idle":"2025-07-29T23:11:21.054174Z","shell.execute_reply.started":"2025-07-29T23:11:20.146379Z","shell.execute_reply":"2025-07-29T23:11:21.053523Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Create function to check if domain name is valid domain name\nVALID_TLDS = ['.com', '.ai', '.io', '.net', '.org', '.co', '.app', '.tech', '.dev']\n\ndef is_valid_domain(domain: str) -> bool:\n    domain = domain.strip().lower()\n\n    # Basic structure check: must contain a valid TLD\n    if not any(domain.endswith(tld) for tld in VALID_TLDS):\n        return False\n\n    # No whitespace\n    if ' ' in domain:\n        return False\n\n    # Length check\n    if len(domain) > 63 or len(domain) == 0:\n        return False\n\n    # Valid characters (alphanumeric, hyphen, and dot)\n    pattern = r'^[a-z0-9\\-\\.]+$'\n    if not re.match(pattern, domain):\n        return False\n\n    # Should not contain multiple dots (e.g., no sentences)\n    if domain.count('.') > 1:\n        return False\n\n    return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:11:21.055036Z","iopub.execute_input":"2025-07-29T23:11:21.055307Z","iopub.status.idle":"2025-07-29T23:11:21.067136Z","shell.execute_reply.started":"2025-07-29T23:11:21.055284Z","shell.execute_reply":"2025-07-29T23:11:21.066450Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# get rouge scorer\nscorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\nscores = []\nbleu_scores = []\nlevenshtein_distances = []\nbrandability_scores = []\npredictions = []\nvalid_domains = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:58:53.563146Z","iopub.execute_input":"2025-07-29T23:58:53.563432Z","iopub.status.idle":"2025-07-29T23:58:53.567502Z","shell.execute_reply.started":"2025-07-29T23:58:53.563413Z","shell.execute_reply":"2025-07-29T23:58:53.566924Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"# Put pytorch model in eval mode\nmodel.eval()\n\n# Loop over test data\nfor item in test_dataset:\n    input_text = item[\"text\"]\n    if \"-> Domain:\" not in input_text:\n        continue\n    description = input_text.split(\"-> Domain:\")[0].replace(\"Business:\", \"\").strip()\n    true_domain = input_text.split(\"-> Domain:\")[-1].strip()\n\n    prompt = f\"Business: {description} -> Domain:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    \n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs, \n            max_new_tokens=20, \n            do_sample=True, \n            top_k=50, \n            temperature=0.7,\n            pad_token_id=tokenizer.pad_token_id,\n            eos_token_id=tokenizer.eos_token_id)\n    \n    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    output_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n    pred_domain = output_text.split(\"-> Domain:\")[-1].split(\"<|\")[0].split(\"\\n\")[0].strip()\n\n    #pred_domain = decoded.split(\"-> Domain:\")[-1].strip()\n\n    # Safety filter\n    banned_keywords = [\"sex\", \"porn\", \"kill\", \"drugs\", \"hate\", \"murder\"]\n    if any(bad in pred_domain.lower() for bad in banned_keywords):\n        pred_domain = \"[REDACTED: Unsafe Output]\"\n\n    # Check if valid domain       \n    valid_domain = is_valid_domain(pred_domain)\n    valid_domains.append(valid_domain)\n    \n    # ROUGE\n    rouge_score = scorer.score(true_domain, pred_domain)[\"rougeL\"].fmeasure\n    scores.append(rouge_score)\n\n    # BLEU\n    bleu = sentence_bleu([true_domain.split(\".\")], pred_domain.split(\".\"), smoothing_function=SmoothingFunction().method1)\n    bleu_scores.append(bleu)\n\n    # Levenshtein\n    lev_distance = Levenshtein.distance(true_domain, pred_domain)\n    levenshtein_distances.append(lev_distance)\n\n    # Brandability heuristic: short, no numbers/symbols, vowel-consonant balance\n    def brandability(domain):\n        score = 1.0\n        if len(domain) > 15: score -= 0.3\n        if any(char.isdigit() or not char.isalnum() for char in domain): score -= 0.3\n        vowels = sum(1 for c in domain if c in \"aeiou\")\n        consonants = sum(1 for c in domain if c.isalpha() and c not in \"aeiou\")\n        ratio = vowels / (consonants + 1)\n        if ratio < 0.2 or ratio > 0.8: score -= 0.2\n        return max(0, round(score, 2))\n\n    brandability_score = brandability(pred_domain)\n    brandability_scores.append(brandability_score)\n\n    predictions.append({\n        \"description\": description,\n        \"true\": true_domain,\n        \"pred\": pred_domain,\n        \"rougeL\": rouge_score,\n        \"bleu\": bleu,\n        \"levenshtein\": lev_distance,\n        \"brandability\": brandability_score,\n        \"is_valid_domain\": valid_domain,\n    })\n\n# Save predictions\nresults_df = pd.DataFrame(predictions)\nresults_df.to_csv(f\"predictions_eval-{VERSION}.csv\", index=False)\n\n# Report average scores\nprint_string = f\"Pct of Predictions that are valid domains = {results_df['is_valid_domain'].mean():.2%}\"\nprint(print_string)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T23:58:54.538352Z","iopub.execute_input":"2025-07-29T23:58:54.538989Z","iopub.status.idle":"2025-07-29T23:59:04.089403Z","shell.execute_reply.started":"2025-07-29T23:58:54.538961Z","shell.execute_reply":"2025-07-29T23:59:04.088768Z"}},"outputs":[{"name":"stdout","text":"Pct of Predictions that are valid domains = 90.00%\n","output_type":"stream"}],"execution_count":136}]}