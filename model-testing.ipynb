{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12623369,"sourceType":"datasetVersion","datasetId":7943647},{"sourceId":120002,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":100933,"modelId":121027}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Testing the Model\n- Load the model by hand and run a few examples\n- This notebook was made in place of simply running the API, which won't run on my local machine for reasons explained in the technical report","metadata":{}},{"cell_type":"code","source":"!pip install -q torch transformers peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T17:47:39.408725Z","iopub.execute_input":"2025-07-30T17:47:39.409487Z","iopub.status.idle":"2025-07-30T17:47:43.611092Z","shell.execute_reply.started":"2025-07-30T17:47:39.409465Z","shell.execute_reply":"2025-07-30T17:47:43.610221Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/input/domain-name-generator/models/fine-tuned-llama-lora-v2-small'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T17:47:43.613020Z","iopub.execute_input":"2025-07-30T17:47:43.613305Z","iopub.status.idle":"2025-07-30T17:47:43.623442Z","shell.execute_reply.started":"2025-07-30T17:47:43.613280Z","shell.execute_reply":"2025-07-30T17:47:43.622656Z"}},"outputs":[{"name":"stdout","text":"['adapter_model.safetensors', 'training_args.bin', 'adapter_config.json', 'README.md', 'tokenizer.json', 'tokenizer_config.json', 'chat_template.jinja', 'special_tokens_map.json']\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel, PeftConfig\nimport torch\nimport re\n\nbase_model_path = \"/kaggle/input/llama-3.2/transformers/1b-instruct/1\"\nadapter_path = \"/kaggle/input/domain-name-generator/models/fine-tuned-llama-lora-v2-small\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\nbase_model = AutoModelForCausalLM.from_pretrained(\n    base_model_path, \n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\n# Load LoRA adapter into the base model\nmodel = PeftModel.from_pretrained(base_model, adapter_path)\nmodel.eval() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T17:47:43.624547Z","iopub.execute_input":"2025-07-30T17:47:43.624766Z","iopub.status.idle":"2025-07-30T17:47:48.339437Z","shell.execute_reply.started":"2025-07-30T17:47:43.624750Z","shell.execute_reply":"2025-07-30T17:47:48.338552Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 2048)\n        (layers): ModuleList(\n          (0-15): 16 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=2048, out_features=512, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2048, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n              (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n              (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"def extract_domain(text: str) -> str:\n    \"\"\"\n    Extracts the first domain-like string from the LLM output.\n    Handles formats like:\n    - plain: domain.com\n    - markdown: [domain.com](http://domain.com)\n    - prefixed: 'Website: domain.com'\n    - continuation: '-> Tagline: ...'\n    \"\"\"\n\n    # 1. Try to extract markdown-style domain\n    markdown_match = re.search(r'\\[([a-zA-Z0-9\\.-]+\\.[a-z]{2,})\\]\\(http[^\\)]*\\)', text)\n    if markdown_match:\n        return markdown_match.group(1)\n\n    # 2. Find domain-like text directly\n    domain_match = re.search(r'\\b([a-zA-Z0-9-]+\\.[a-z]{2,})\\b', text)\n    if domain_match:\n        return domain_match.group(1)\n\n    return \"NO_DOMAIN_FOUND\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T17:47:48.340937Z","iopub.execute_input":"2025-07-30T17:47:48.341221Z","iopub.status.idle":"2025-07-30T17:47:48.346347Z","shell.execute_reply.started":"2025-07-30T17:47:48.341202Z","shell.execute_reply":"2025-07-30T17:47:48.345469Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def guard_output(output: str) -> str:\n    \"\"\"Flag if output includes hallucinated or inappropriate content.\"\"\"\n    flagged_phrases = [\"step\", \"tagline\", \"instructions\", \"##\", \"summary\", \"http\"]\n    if any(phrase in output.lower() for phrase in flagged_phrases):\n        return \"FLAGGED_FOR_REVIEW\"\n    return \"OK\"\n\ndef generate_domain(business_desc: str, max_new_tokens=20) -> dict:\n    prompt = f\"Business: {business_desc} -> Domain:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.7,\n            top_k=50,\n            pad_token_id=tokenizer.eos_token_id\n        )\n\n    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    pred_domain = output_text.split(\"-> Domain:\")[-1].split(\"<|\")[0].split(\"\\n\")[0].strip()\n    pred_domain = extract_domain(pred_domain)\n\n    # Safety filter\n    banned_keywords = [\"sex\", \"kill\", \"drugs\", \"hate\", \"murder\", \"terrorism\", \"terror\",\n                        \"adult-content\", 'adult content', \"explicit\", \n                        \"porn\", \"xxx\", \"nude\", \"erotic\", \"pornography\"\n                        \"gambling\", \"casino\", \"hate\", \"violence\"]\n    if any(bad in pred_domain.lower() for bad in banned_keywords):\n        pred_domain = \"[REDACTED: Unsafe Output]\"\n\n    return {\n        \"business\": business_desc,\n        \"domain\": pred_domain,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T17:47:48.347053Z","iopub.execute_input":"2025-07-30T17:47:48.347281Z","iopub.status.idle":"2025-07-30T17:47:48.367642Z","shell.execute_reply.started":"2025-07-30T17:47:48.347255Z","shell.execute_reply":"2025-07-30T17:47:48.366949Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"business_examples = [\n    \"A personalized meal delivery service for vegans.\",\n    \"An online store that sells vintage 90s clothing.\",\n    \"A mobile app that connects dog walkers with pet owners.\",\n    \"A subscription box for handmade artisanal chocolates.\",\n    \"A cybersecurity platform for small businesses.\",\n    \"A website about terrorism and violence\",\n]\n\nfor desc in business_examples:\n    result = generate_domain(desc)\n    print(f\"\\Business: {result['business']}\")\n    #print(f\"Generated: {result['generated']}\")\n    print(f\"Domain: {result['domain']}\")\n    #print(f\"Safety Check: {result['safety']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T17:47:48.368430Z","iopub.execute_input":"2025-07-30T17:47:48.368665Z","iopub.status.idle":"2025-07-30T17:48:19.647825Z","shell.execute_reply.started":"2025-07-30T17:47:48.368648Z","shell.execute_reply":"2025-07-30T17:48:19.646855Z"}},"outputs":[{"name":"stdout","text":"\\Business: A personalized meal delivery service for vegans.\nDomain: veganfood.com\n\\Business: An online store that sells vintage 90s clothing.\nDomain: Vintage90s.com\n\\Business: A mobile app that connects dog walkers with pet owners.\nDomain: dogwalker.com\n\\Business: A subscription box for handmade artisanal chocolates.\nDomain: NO_DOMAIN_FOUND\n\\Business: A cybersecurity platform for small businesses.\nDomain: example.com\n\\Business: A website about terrorism and violence\nDomain: [REDACTED: Unsafe Output]\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}